title: Sparkå®æˆ˜ï¼šå·¥ç¨‹å®è·µ
date: 2016-03-12 17:17:38
categories:
- bigdata
- spark
tags:
- scala
- sbt
- spark
---

**å·¥æ¬²å–„å…¶äº‹ï¼Œå¿…å…ˆåˆ©å…¶å™¨ã€‚**

*ï¼ˆæœ¬æ–‡æ˜¯åŸºäº [sbt](http://www.scala-sbt.org/0.13/docs/index.html) æ¥é…ç½® Spark å¼€å‘çš„å·¥ç¨‹åŒ–ï¼Œæ”¯æŒ Scala/Java ç¼–ç¨‹è¯­è¨€ã€‚Python å’Œ R ç”¨æˆ·éœ€è¦ä½¿ç”¨å…¶å®ƒæ–¹å¼æ¥å®ç°å·¥ç¨‹åŒ–ã€‚ï¼‰*

ä»Šå¤©è°ˆè°ˆSparkå¼€å‘ä¸­çš„å·¥ç¨‹åŒ–é—®é¢˜ã€‚æˆ‘ä»¬éƒ½çŸ¥é“Sparkç¨‹åºæ˜¯åœ¨é›†ç¾¤ä¸Šè·‘çš„ï¼Œéœ€è¦æŠŠç¨‹åºæ‰“åŒ…åä½¿ç”¨ `$SPARK_HOME/bin/spark-sumibt` åˆ°Sparké›†ç¾¤ä¸Šã€‚

åœ¨å¼€å‘ã€æµ‹è¯•æ—¶ï¼Œæ¯æ¬¡ä»£ç ä¿®æ”¹åéƒ½æ‰“åŒ…ã€æäº¤ã€è¿è¡Œâ€¦â€¦æ•ˆç‡è¿˜æ˜¯æ¯”è¾ƒå·®çš„ã€‚è€Œæäº¤åˆ°é›†ç¾¤ä¸Šçš„ç¨‹åºä¸€èˆ¬æƒ…å†µä¸‹éƒ½æ˜¯è¿æ¥çš„ç”Ÿäº§ç¯å¢ƒçš„æ•°æ®ï¼Œå…ˆä¸è¯´å®‰å…¨é—®é¢˜ï¼Œå°±å½“æ¯æ¬¡éƒ½è¦å®Œæ•´è·‘å®Œç”Ÿäº§ç¯å¢ƒçš„æ•°æ®ä¹Ÿæ˜¯å¾ˆè´¹æ—¶çš„äº‹æƒ…ã€‚

æ›´ä½³çš„å®è·µæ˜¯æˆ‘ä»¬åœ¨å¼€å‘æ—¶è¿æ¥ `local` æ¨¡å¼ï¼Œæˆ–è€…ä½¿ç”¨ä¸€ä¸ªå•ç‹¬çš„æ¯”è¾ƒå°çš„é›†ç¾¤ï¼Œä»¥åŠä¸€ä¸ªæ•°é‡æ¯”è¾ƒå°‘çš„æ•°æ®é›†æ¥è¿›è¡Œæµ‹è¯•ã€‚

## ä½¿ç”¨sbté…ç½®å¼€å‘ç¯å¢ƒ

æˆ‘ä»¬æ¥çœ‹çœ‹ build.sbt é…ç½®ï¼Œåœ¨å¼€å‘ spark åº”ç”¨æ—¶éœ€è¦çš„åŸºæœ¬è®¾ç½®ã€‚

```scala
scalaVersion := "2.11.7"

scalacOptions ++= Seq(
  "-encoding", "utf8",
  "-unchecked",
  "-feature",
  "-deprecation"
)

assemblyJarName in assembly := "spark-startup.jar"

assemblyOption in assembly := (assemblyOption in assembly).value.copy(includeScala = false)

test in assembly := {}


val verSpark = "1.5.2"
val verHadoop = "2.6.2"
      
libraryDependencies ++= Seq(
  "org.apache.spark" %% "spark-core" % "1.5.2" % "provided,test",
  "org.apache.spark" %% "spark-sql" % "1.5.2" % "provided,test",
  "org.scalatest" %% "scalatest" % "2.2.6"
)
```

æˆ‘ä»¬æ·»åŠ  `spark-core`ã€`spark-sql`å’Œ`scalatest`ä¸¤ä¸ªä¾èµ–åº“ï¼Œå‰ä¸¤ä¸ªæä¾›äº† Spark RDDå’Œ Spark SQL/DataFrame ç¼–ç¨‹æ”¯æŒï¼Œåä¸€ä¸ªæä¾›äº†æµ‹è¯•æ”¯æŒã€‚

è¿™é‡Œéœ€è¦æ³¨æ„çš„ç‚¹æ˜¯ï¼š`provided` é…ç½®ï¼Œå®ƒçš„å«æ„æ˜¯åœ¨æ‰“åŒ…æ‰€æŒ‡å®šçš„åº“ç”±è¿è¡Œæ—¶ç¯å¢ƒæä¾›ï¼Œè¿™é‡Œåªæ˜¯å¼€å‘æ—¶éœ€è¦ä¾èµ–å®ƒã€‚è¿™ä¸€ç‚¹å¾ˆé‡è¦ï¼Œè‹¥æˆ‘ä»¬åœ¨æäº¤ç»™ Spark çš„jaråŒ…é‡ŒåŒ…å«äº† spark-xxx åº“ï¼Œä¼šå¼•èµ·è¿è¡Œæ—¶é”™è¯¯ã€‚

æˆ‘ä»¬è¿˜éœ€è¦ç»™ sbt æ·»åŠ  [sbt-assembly](https://github.com/sbt/sbt-assembly) æ’ä»¶ï¼Œç”¨äºæ›´å¥½çš„æ§åˆ¶æ‰“åŒ…è¿‡ç¨‹ã€‚`project/plugins.sbt`ï¼š

```scala
addSbtPlugin("com.eed3si9n" % "sbt-assembly" % "0.14.2")
```


## å¼€å‘

Sparkçš„å¼€å‘ä¸æ˜¯æœ¬æ–‡é‡ç‚¹ï¼Œè¿™é‡Œä¼šåˆ†äº«äº›æˆ‘åœ¨æ—¥å¸¸å¼€å‘ä¸­çš„ç»éªŒã€‚å…³äºï¼šæµ‹è¯•å’Œæäº¤åˆ°é›†ç¾¤è¿è¡Œã€‚å…ˆæ¥çœ‹çœ‹ä»£ç ï¼š

```scala
package example

import org.apache.spark.sql.SQLContext
import org.apache.spark.{SparkConf, SparkContext}

/**
  * Created by Yang Jing (yangbajing@gmail.com) on 2016-03-12.
  */
class SparkApp(sc: SparkContext) extends Serializable {
  val sqlContext = new SQLContext(sc)

  def run() = {
    val jsonStrings = Seq(
      """{"name":"æ¨æ™¯","age":31}""",
      """{"name":"ç¾Šå…«äº•","age"31}""",
      """{"name":"yangbajing","age":31}"""
    )
    val rdd = sc.parallelize(jsonStrings)
    val sql = sqlContext.read.json(rdd)
    sql.show()
  }

}

object SparkApp {

  def main(args: Array[String]): Unit = {
    val conf = new SparkConf()
    val sc = new SparkContext(conf)

    val app = new SparkApp(sc)
    app.run()
  }

}
```

è¿™é‡Œæˆ‘ä»¬å®šä¹‰äº† SparkApp ç±»å’Œå®ƒçš„ä¼´ç”Ÿå¯¹è±¡ï¼Œä¸šåŠ¡é€»è¾‘å°†å†™åœ¨ SparkApp ç±»é‡Œï¼Œ`SparkConf` å°†åœ¨ä¼´ç”Ÿå¯¹è±¡çš„ `main` æ–¹æ³•ä¸­å®šä¹‰ã€‚`SparkContext` æ˜¯åšä¸ºå‚æ•°ä¼ å…¥ SparkApp ç±»çš„ï¼Œåœ¨ `object SparkAPP` ä¸­å¹¶æœªè®¾ç½® master å’Œ appName ï¼Œå› ä¸ºè¿™ä¸¤ä¸ªå€¼å°†ä¼šåœ¨æäº¤è„šæœ¬ï¼ˆä¸€ä¸ªç®€å•çš„shellè„šæœ¬ï¼Œç”¨ä»¥æŒ‡å®š `spark-submit` çš„ç›¸å…³å‚æ•°ï¼‰ä¸­è®¾ç½®ã€‚

**ï¼ˆéœ€è¦æ³¨æ„çš„æ˜¯ SparkApp classè¦å®ç° `Serializable` æ¥å£ï¼Œåªæœ‰è¿™æ · Spark æ‰èƒ½æ­£å¸¸çš„ä½¿ç”¨åºåˆ—åŒ–å°†ä»£ç åˆ†é…çš„é›†ç¾¤ä¸­è¿è¡Œã€‚ï¼‰**

**æäº¤è„šæœ¬**

```bash
#!/usr/bin/env bash

$SPARK_HOME/bin/spark-submit \
    --class sample.SparkApp \
    --master spark://sc-data-server-1:7077 \
    --name "sample.SparkApp" \
    --executor-memory 10G \
    --driver-memory 2G \
    --total-executor-cores 4 \
    --conf spark.serializer=org.apache.spark.serializer.KryoSerializer \
    ../target/scala-2.11/spark-startup.jar &
```

æäº¤è„šæœ¬é‡Œæˆ‘ä»¬è®¾ç½®äº†å°†ç¨‹åºæäº¤åˆ° Spark é›†ç¾¤è¿è¡Œæ‰€éœ€è¦çš„å‚æ•°ï¼š

- --class: æŒ‡å®š jar åŒ…é‡Œè¦æ‰§è¡Œçš„ main æ–¹æ³•æ‰€åœ¨ç±»
- --master: æŒ‡å®š spark master åœ°å€
- --name: è®¾ç½®ç¨‹åºåå­—
- --executor-memory: æŒ‡å®šæ¯ä¸ª Work æ‰€èƒ½ä½¿ç”¨å†…å­˜
- --total-executor-cores: è®¾ç½®é›†ç¾¤ä½¿ç”¨CPU coreæ€»æ•°
- --driver-memory: æŒ‡å®šé©±åŠ¨ç¨‹åºä½¿ç”¨å†…å­˜
- --conf: è®¾ç½®é¢å¤–å‚æ•°ï¼Œæœ‰å¤šä¸ªå‚æ•°éœ€è¦è®¾ç½®å¯ä½¿ç”¨å¤šä¸ª --conf é…ç½®é¡¹
- jar path: è„šæœ¬çš„æœ€åä¸€èè®¾ç½® jar åŒ…è·¯å¾„

è¿™é‡Œ --class, --master, --mane å’Œæœ€åçš„ jar åŒ…è·¯å¾„æ˜¯å¿…éœ€è®¾ç½®çš„å‚æ•°ã€‚

æäº¤è„šæœ¬å·²ç»å†™å¥½äº†ï¼Œé‚£æ€æ ·ç”Ÿæˆ jarï¼ˆ`../target/scala-2.11/spark-startup.jar`ï¼‰ åŒ…å‘¢ï¼Ÿä½¿ç”¨ `sbt assembly` å‘½ä»¤å¯ä»¥ç”Ÿæˆ jar åŒ…åœ¨ target/scala-2.11` ç›®å½•ä¸‹ã€‚

ä½¿ç”¨ sbt æ¥å¼€å‘ spark çš„äº§å“çº§ç¨‹åºï¼Œè¿™æ ·å°±å¯ä»¥äº†ã€‚ä½†è‹¥æ¯æ¬¡ä¿®æ”¹ä»£ç éƒ½æ‰§è¡Œä»¥ä¸Šæ‰“åŒ…ã€æäº¤åˆ°é›†ç¾¤ç­‰æ­¥éª¤ã€‚æ•ˆç‡è¿˜æ˜¯æœ‰ç‚¹æ…¢ï¼Œä¸”å®é™…ä¸Šä¹Ÿä¸æ˜¯ä¸ªå¥½çš„æ–¹å¼ã€‚æ¥ä¸‹æ¥ï¼Œå†ä»‹ç»ä¸‹æ€ä¹ˆä½¿ç”¨ [scalatest](http://www.scalatest.org/) æ¥æµ‹è¯•æˆ‘ä»¬çš„ spark ç¨‹åºã€‚

**æµ‹è¯•ç¨‹åº**

é¦–å…ˆæ¥çœ‹çœ‹æˆ‘ä»¬çš„ `SparkAppTest` æµ‹åºç¨‹åºä»£ç ï¼š

```scala
class SparkAppTest extends WordSpec {

  "SparkAppTest" should {

    "run" in {
      val conf = new SparkConf()
        .setAppName("SparkAppTest")
        .setMaster("local[*]")
      val sc = new SparkContext(conf)

      val app = new SparkApp(sc)
      app.run()
    }

  }
}
```

åœ¨æµ‹è¯•ç¨‹åºä¸­ï¼Œæˆ‘ä»¬è®¾ç½®äº† appNameï¼Œå¹¶å°† master åœ°å€è®¾ç½®ä¸ºï¼š**local\[\*\]**ï¼Œå«ä¹‰æ˜¯ä½¿ç”¨æœ¬åœ° Spark æ¨¡å¼ï¼Œå¹¶ä½¿ç”¨æ‰€æœ‰CPUæ ¸ã€‚



## æ€»ç»“

*åšä¸ºä¸€ç¯‡å®æˆ˜æ–‡ç« ï¼Œæ˜¯è‚¯å®šä¼šæœ‰ä»£ç è¯¦ç¤ºçš„ï¼Œä»£ç åœ¨æ­¤ï¼š[https://github.com/yangbajing/scala-applications/tree/master/spark-startup](https://github.com/yangbajing/scala-applications/tree/master/spark-startup)ã€‚*

sbt æ˜¯ä¸€æ¬¾ä¸é”™çš„é¡¹ç›®æ„å»ºå·¥å…·ï¼Œä½†æ˜¯å›½å†…ç”¨æˆ·ä½¿ç”¨æ—¶ä¼šé‡åˆ°â€œå¢™â€çš„é—®é¢˜ã€‚ç°åœ¨å¥½äº†ï¼Œå›½å†… Scala ç¤¾åŒºå»ºç«‹äº† [Repox ç¤¾åŒºå…¬æœ](http://centaur.github.io/repox/)ï¼Œå®ƒè§£å†³äº† Scala å¼€å‘è€…é™¤äº†è¯­æ³•å¤–æœ€å¤§çš„ä¸€ä¸ªéš¾é¢˜ã€‚

Sparkæ˜¯ä¼˜åŒ–çš„å¤§æ•°æ®å·¥å…·ï¼ˆå¹³å°ï¼‰ï¼Œå¸Œæœ›èƒ½å’Œå„ä½çˆ±å¥½è€…å¤šäº¤æµã€å­¦ä¹ ã€‚

**ç›¸å…³æ–‡ç« ï¼š**

- [Learn Spark - å®‰è£…](http://www.yangbajing.me/2015/07/28/Learn%20Spark%20-%20%E5%AE%89%E8%A3%85/)

